# tools/alert_sanity_check.py
"""
Compare alerts to training distribution using z-scores.
Usage:
    python tools/alert_sanity_check.py \
        --train detector/features/capture_20250905_125133_flow_features.json \
        --alerts detector/alerts/alerts.json \
        --top 20
"""

import json
import math
import argparse
from pathlib import Path
from statistics import mean, pstdev

DEFAULT_FEATURES = [
    "log_duration","log_bytes","log_pkts","bytes_per_pkt","pps","bps",
    "out_in_ratio","dir_pkt_ratio","syn_only","rst_ratio","fin_present",
    "ack_present","proto_is_tcp","dst_port_bin","flow_size_class",
    "same_subnet_v4","is_priv_to_public"
]

def load_json(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def compute_stats(rows, features):
    stats = {}
    for feat in features:
        vals = []
        for r in rows:
            v = r.get(feat)
            try:
                v = float(v)
                if math.isfinite(v):
                    vals.append(v)
            except Exception:
                continue
        if len(vals) < 2:
            stats[feat] = {"mean": 0.0, "std": 1.0}
        else:
            stats[feat] = {"mean": mean(vals), "std": pstdev(vals) or 1.0}
    return stats

def zscore(val, mu, sigma):
    if sigma == 0:
        return 0.0
    return (val - mu) / sigma

def summarize_alert(alert, stats, features, top_n=5):
    feat_map = alert.get("features", alert.get("features", {}))
    zs = []
    for f in features:
        try:
            v = float(feat_map.get(f, 0.0))
        except Exception:
            v = 0.0
        mu = stats[f]["mean"]
        sd = stats[f]["std"]
        z = zscore(v, mu, sd)
        zs.append((f, v, mu, sd, z))
    zs.sort(key=lambda x: abs(x[4]), reverse=True)
    top = zs[:top_n]
    return top

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--train", required=True, help="training features JSON (used to compute stats)")
    ap.add_argument("--alerts", required=True, help="alerts JSON generated by your scoring")
    ap.add_argument("--top", type=int, default=20, help="how many top alerts to inspect")
    ap.add_argument("--features", nargs="*", default=DEFAULT_FEATURES, help="feature names to include")
    args = ap.parse_args()

    train_rows = load_json(args.train)
    alerts = load_json(args.alerts)

    stats = compute_stats(train_rows, args.features)

    print(f"[info] computed stats on {len(train_rows)} training rows")
    for i, alert in enumerate(alerts[: args.top], start=1):
        print("\n" + "="*60)
        print(f"Alert rank {i}  score={alert.get('anomaly_score'):.6f} pred={alert.get('prediction')}")
        trace = alert.get("trace", {})
        print("trace:", trace)
        top = summarize_alert(alert, stats, args.features, top_n=6)
        print("Top feature deviations (feature, value, mean, std, z):")
        for t in top:
            fname, val, mu, sd, z = t
            print(f"  {fname:20s} val={val:.6g} mean={mu:.6g} std={sd:.6g}  z={z:.3f}")
    print("\n[done]")

if __name__ == "__main__":
    main()
